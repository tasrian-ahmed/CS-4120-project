{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e61102a-5760-4d00-a6cb-8b40a1c3a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 936 201 201\n",
      "Train median charges: 9545.63\n",
      "Feature matrix shape: (936, 17)\n",
      "\n",
      "=== Training classification NNs ===\n",
      "Config clf_small: hidden=(32, 16), alpha=0.001, lr=0.001\n",
      "  Final val F1 = 0.9215\n",
      "Config clf_medium: hidden=(64, 32), alpha=0.001, lr=0.0005\n",
      "  Final val F1 = 0.9110\n",
      "\n",
      "Best classification NN: clf_small with final val F1 = 0.9215\n",
      "\n",
      "=== Training regression NNs ===\n",
      "Config reg_small: hidden=(32, 16), alpha=0.001, lr=0.001\n",
      "  Final val RMSE = 4521.07\n",
      "Config reg_medium: hidden=(64, 32), alpha=0.001, lr=0.0005\n",
      "  Final val RMSE = 4370.82\n",
      "\n",
      "Best regression NN: reg_medium with final val RMSE = 4370.82\n",
      "Saved Plot 1 (classification learning curve) to ../plots/plot1_nn_class_learning_curve.png\n",
      "Saved Plot 2 (regression learning curve) to ../plots/plot2_nn_reg_learning_curve.png\n",
      "\n",
      "=== NN classification metrics ===\n",
      "Val  - Acc: 0.9254, F1: 0.9215, ROC-AUC: 0.9620\n",
      "Test - Acc: 0.9154, F1: 0.9091, ROC-AUC: 0.9432\n",
      "\n",
      "=== NN regression metrics ===\n",
      "Val  - MAE: 2543.74, RMSE: 4370.82\n",
      "Test - MAE: 2628.06, RMSE: 5046.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf': {'val_accuracy': 0.9253731343283582,\n",
       "  'val_f1': 0.9214659685863874,\n",
       "  'val_roc_auc': 0.961970570689998,\n",
       "  'test_accuracy': 0.9154228855721394,\n",
       "  'test_f1': 0.9090909090909091,\n",
       "  'test_roc_auc': 0.943154761904762},\n",
       " 'reg': {'val_mae': 2543.7399166354776,\n",
       "  'val_rmse': 4370.820926757592,\n",
       "  'test_mae': 2628.0644409321676,\n",
       "  'test_rmse': 5046.45493640548}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Imports & config ---\n",
    "import os, math, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 4120\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"../data/insurance.csv\"\n",
    "PLOTS_DIR = \"../plots\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load data and create targets (same logic as midpoint) ---\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# enforce dtypes\n",
    "cat_cols = [\"sex\", \"smoker\", \"region\"]\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# engineered features\n",
    "df[\"bmi_obese\"] = (df[\"bmi\"] >= 30).astype(int)\n",
    "df[\"age_band\"]  = pd.cut(\n",
    "    df[\"age\"],\n",
    "    bins=[17, 25, 35, 45, 55, 65],\n",
    "    labels=[\"18-25\",\"26-35\",\"36-45\",\"46-55\",\"56-65\"],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# split once\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, shuffle=True)\n",
    "val_df,   test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "train_median = train_df[\"charges\"].median()\n",
    "\n",
    "def add_targets(d, median):\n",
    "    d = d.copy()\n",
    "    d[\"y_class\"] = (d[\"charges\"] >= median).astype(int)   # high vs low cost\n",
    "    d[\"y_reg\"]   = d[\"charges\"].astype(float)\n",
    "    return d\n",
    "\n",
    "train_df = add_targets(train_df, train_median)\n",
    "val_df   = add_targets(val_df,   train_median)\n",
    "test_df  = add_targets(test_df,  train_median)\n",
    "\n",
    "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "print(\"Train median charges:\", round(train_median, 2))\n",
    "\n",
    "# --- 2. Preprocessing for NN (fit on train, transform to dense arrays) ---\n",
    "\n",
    "num_cols = [\"age\", \"bmi\", \"children\", \"bmi_obese\"]\n",
    "cat_cols = [\"sex\", \"smoker\", \"region\", \"age_band\"]\n",
    "\n",
    "numeric_tf     = StandardScaler()\n",
    "categorical_tf = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_tf, num_cols),\n",
    "        (\"cat\", categorical_tf, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_raw = train_df[num_cols + cat_cols]\n",
    "X_val_raw   = val_df[num_cols + cat_cols]\n",
    "X_test_raw  = test_df[num_cols + cat_cols]\n",
    "\n",
    "y_train_class = train_df[\"y_class\"].values\n",
    "y_val_class   = val_df[\"y_class\"].values\n",
    "y_test_class  = test_df[\"y_class\"].values\n",
    "\n",
    "y_train_reg = train_df[\"y_reg\"].values\n",
    "y_val_reg   = val_df[\"y_reg\"].values\n",
    "y_test_reg  = test_df[\"y_reg\"].values\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_reg_scaled = y_scaler.fit_transform(y_train_reg.reshape(-1, 1)).ravel()\n",
    "y_val_reg_scaled   = y_scaler.transform(y_val_reg.reshape(-1, 1)).ravel()\n",
    "y_test_reg_scaled  = y_scaler.transform(y_test_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "# fit on train, transform all\n",
    "X_train = preprocess.fit_transform(X_train_raw)\n",
    "X_val   = preprocess.transform(X_val_raw)\n",
    "X_test  = preprocess.transform(X_test_raw)\n",
    "\n",
    "# make sure dense\n",
    "if hasattr(X_train, \"toarray\"):\n",
    "    X_train = X_train.toarray()\n",
    "    X_val   = X_val.toarray()\n",
    "    X_test  = X_test.toarray()\n",
    "\n",
    "print(\"Feature matrix shape:\", X_train.shape)\n",
    "\n",
    "# --- 3. Helper: training loop for MLPClassifier (classification NN) ---\n",
    "\n",
    "def train_mlp_classifier(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    alpha=1e-3,\n",
    "    lr=1e-3,\n",
    "    epochs=80,\n",
    "):\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=1,           # we will loop manually\n",
    "        warm_start=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    classes = np.unique(y_tr)\n",
    "\n",
    "    train_f1_list = []\n",
    "    val_f1_list   = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list   = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        clf.partial_fit(X_tr, y_tr, classes=classes)\n",
    "\n",
    "        # metrics on train\n",
    "        y_tr_pred = clf.predict(X_tr)\n",
    "        train_f1  = f1_score(y_tr, y_tr_pred)\n",
    "        train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "\n",
    "        # metrics on val\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        val_f1  = f1_score(y_val, y_val_pred)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "        train_f1_list.append(train_f1)\n",
    "        val_f1_list.append(val_f1)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "    history = {\n",
    "        \"train_f1\": train_f1_list,\n",
    "        \"val_f1\":   val_f1_list,\n",
    "        \"train_acc\": train_acc_list,\n",
    "        \"val_acc\":   val_acc_list,\n",
    "    }\n",
    "    return clf, history\n",
    "\n",
    "# --- 4. Helper: training loop for MLPRegressor (regression NN) ---\n",
    "\n",
    "def train_mlp_regressor(\n",
    "    X_tr, y_tr_scaled, X_val, y_val_scaled,\n",
    "    y_tr_orig, y_val_orig,\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    alpha=1e-3,\n",
    "    lr=1e-3,\n",
    "    epochs=80,\n",
    "    y_scaler=None,\n",
    "):\n",
    "    reg = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=1,\n",
    "        warm_start=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    train_rmse_list = []\n",
    "    val_rmse_list   = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train on scaled targets\n",
    "        reg.partial_fit(X_tr, y_tr_scaled)\n",
    "\n",
    "        # Predictions in scaled space\n",
    "        y_tr_pred_scaled  = reg.predict(X_tr)\n",
    "        y_val_pred_scaled = reg.predict(X_val)\n",
    "\n",
    "        # Convert back to original dollar scale for metrics\n",
    "        if y_scaler is not None:\n",
    "            y_tr_pred = y_scaler.inverse_transform(\n",
    "                y_tr_pred_scaled.reshape(-1, 1)\n",
    "            ).ravel()\n",
    "            y_val_pred = y_scaler.inverse_transform(\n",
    "                y_val_pred_scaled.reshape(-1, 1)\n",
    "            ).ravel()\n",
    "        else:\n",
    "            y_tr_pred = y_tr_pred_scaled\n",
    "            y_val_pred = y_val_pred_scaled\n",
    "\n",
    "        # ✅ Use y_tr_orig and y_val_orig here (NOT y_tr / y_val)\n",
    "        train_rmse = math.sqrt(mean_squared_error(y_tr_orig, y_tr_pred))\n",
    "        val_rmse   = math.sqrt(mean_squared_error(y_val_orig, y_val_pred))\n",
    "\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        val_rmse_list.append(val_rmse)\n",
    "\n",
    "    history = {\n",
    "        \"train_rmse\": train_rmse_list,\n",
    "        \"val_rmse\":   val_rmse_list,\n",
    "    }\n",
    "    return reg, history\n",
    "\n",
    "\n",
    "# --- 5. Small hyperparameter grids (very small, but enough for report) ---\n",
    "\n",
    "clf_configs = [\n",
    "    {\"name\": \"clf_small\",  \"hidden\": (32, 16), \"alpha\": 1e-3, \"lr\": 1e-3},\n",
    "    {\"name\": \"clf_medium\", \"hidden\": (64, 32), \"alpha\": 1e-3, \"lr\": 5e-4},\n",
    "]\n",
    "\n",
    "reg_configs = [\n",
    "    {\"name\": \"reg_small\",  \"hidden\": (32, 16), \"alpha\": 1e-3, \"lr\": 1e-3},\n",
    "    {\"name\": \"reg_medium\", \"hidden\": (64, 32), \"alpha\": 1e-3, \"lr\": 5e-4},\n",
    "]\n",
    "\n",
    "best_clf = None\n",
    "best_clf_hist = None\n",
    "best_clf_name = None\n",
    "best_clf_val_f1 = -1\n",
    "\n",
    "print(\"\\n=== Training classification NNs ===\")\n",
    "for cfg in clf_configs:\n",
    "    print(f\"Config {cfg['name']}: hidden={cfg['hidden']}, alpha={cfg['alpha']}, lr={cfg['lr']}\")\n",
    "    model, hist = train_mlp_classifier(\n",
    "        X_train, y_train_class,\n",
    "        X_val,   y_val_class,\n",
    "        hidden_layer_sizes=cfg[\"hidden\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        epochs=80,\n",
    "    )\n",
    "    final_val_f1 = hist[\"val_f1\"][-1]\n",
    "    print(f\"  Final val F1 = {final_val_f1:.4f}\")\n",
    "    if final_val_f1 > best_clf_val_f1:\n",
    "        best_clf_val_f1 = final_val_f1\n",
    "        best_clf = model\n",
    "        best_clf_hist = hist\n",
    "        best_clf_name = cfg[\"name\"]\n",
    "\n",
    "print(f\"\\nBest classification NN: {best_clf_name} with final val F1 = {best_clf_val_f1:.4f}\")\n",
    "\n",
    "best_reg = None\n",
    "best_reg_hist = None\n",
    "best_reg_name = None\n",
    "best_reg_val_rmse = float(\"inf\")\n",
    "\n",
    "print(\"\\n=== Training regression NNs ===\")\n",
    "for cfg in reg_configs:\n",
    "    print(f\"Config {cfg['name']}: hidden={cfg['hidden']}, alpha={cfg['alpha']}, lr={cfg['lr']}\")\n",
    "    model, hist = train_mlp_regressor(\n",
    "        X_train, y_train_reg_scaled,\n",
    "        X_val,   y_val_reg_scaled,\n",
    "        y_train_reg, y_val_reg,\n",
    "        hidden_layer_sizes=cfg[\"hidden\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        epochs=80,\n",
    "        y_scaler=y_scaler,\n",
    "    )\n",
    "    final_val_rmse = hist[\"val_rmse\"][-1]\n",
    "    print(f\"  Final val RMSE = {final_val_rmse:.2f}\")\n",
    "    if final_val_rmse < best_reg_val_rmse:\n",
    "        best_reg_val_rmse = final_val_rmse\n",
    "        best_reg = model\n",
    "        best_reg_hist = hist\n",
    "        best_reg_name = cfg[\"name\"]\n",
    "\n",
    "print(f\"\\nBest regression NN: {best_reg_name} with final val RMSE = {best_reg_val_rmse:.2f}\")\n",
    "\n",
    "# --- 6. Plot learning curves (required Plot 1 & Plot 2) ---\n",
    "\n",
    "# Plot 1 – classification NN learning curve (train/val F1 vs epochs)\n",
    "epochs = range(1, len(best_clf_hist[\"train_f1\"]) + 1)\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(epochs, best_clf_hist[\"train_f1\"], label=\"Train F1\")\n",
    "ax.plot(epochs, best_clf_hist[\"val_f1\"],   label=\"Val F1\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"F1 score\")\n",
    "ax.set_title(f\"Classification NN learning curve ({best_clf_name})\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plot1_path = os.path.join(PLOTS_DIR, \"plot1_nn_class_learning_curve.png\")\n",
    "plt.savefig(plot1_path, dpi=160)\n",
    "plt.close()\n",
    "print(f\"Saved Plot 1 (classification learning curve) to {plot1_path}\")\n",
    "\n",
    "# Plot 2 – regression NN learning curve (train/val RMSE vs epochs)\n",
    "epochs = range(1, len(best_reg_hist[\"train_rmse\"]) + 1)\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(epochs, best_reg_hist[\"train_rmse\"], label=\"Train RMSE\")\n",
    "ax.plot(epochs, best_reg_hist[\"val_rmse\"],   label=\"Val RMSE\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_title(f\"Regression NN learning curve ({best_reg_name})\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plot2_path = os.path.join(PLOTS_DIR, \"plot2_nn_reg_learning_curve.png\")\n",
    "plt.savefig(plot2_path, dpi=160)\n",
    "plt.close()\n",
    "print(f\"Saved Plot 2 (regression learning curve) to {plot2_path}\")\n",
    "\n",
    "# --- 7. Final NN metrics on validation and test (for report tables) ---\n",
    "\n",
    "# Classification NN metrics\n",
    "y_val_pred_clf  = best_clf.predict(X_val)\n",
    "y_test_pred_clf = best_clf.predict(X_test)\n",
    "\n",
    "try:\n",
    "    y_val_prob_clf  = best_clf.predict_proba(X_val)[:,1]\n",
    "    y_test_prob_clf = best_clf.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    y_val_prob_clf  = y_val_pred_clf\n",
    "    y_test_prob_clf = y_test_pred_clf\n",
    "\n",
    "nn_clf_val_accuracy = accuracy_score(y_val_class, y_val_pred_clf)\n",
    "nn_clf_val_f1       = f1_score(y_val_class, y_val_pred_clf)\n",
    "nn_clf_val_roc_auc  = roc_auc_score(y_val_class, y_val_prob_clf)\n",
    "\n",
    "nn_clf_test_accuracy = accuracy_score(y_test_class, y_test_pred_clf)\n",
    "nn_clf_test_f1       = f1_score(y_test_class, y_test_pred_clf)\n",
    "nn_clf_test_roc_auc  = roc_auc_score(y_test_class, y_test_prob_clf)\n",
    "\n",
    "print(\"\\n=== NN classification metrics ===\")\n",
    "print(f\"Val  - Acc: {nn_clf_val_accuracy:.4f}, F1: {nn_clf_val_f1:.4f}, ROC-AUC: {nn_clf_val_roc_auc:.4f}\")\n",
    "print(f\"Test - Acc: {nn_clf_test_accuracy:.4f}, F1: {nn_clf_test_f1:.4f}, ROC-AUC: {nn_clf_test_roc_auc:.4f}\")\n",
    "\n",
    "# Regression NN metrics (convert predictions back to original scale)\n",
    "y_val_pred_reg_scaled  = best_reg.predict(X_val)\n",
    "y_test_pred_reg_scaled = best_reg.predict(X_test)\n",
    "\n",
    "y_val_pred_reg = y_scaler.inverse_transform(\n",
    "    y_val_pred_reg_scaled.reshape(-1, 1)\n",
    ").ravel()\n",
    "y_test_pred_reg = y_scaler.inverse_transform(\n",
    "    y_test_pred_reg_scaled.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "nn_reg_val_mae  = mean_absolute_error(y_val_reg, y_val_pred_reg)\n",
    "nn_reg_val_rmse = math.sqrt(mean_squared_error(y_val_reg, y_val_pred_reg))\n",
    "\n",
    "nn_reg_test_mae  = mean_absolute_error(y_test_reg, y_test_pred_reg)\n",
    "nn_reg_test_rmse = math.sqrt(mean_squared_error(y_test_reg, y_test_pred_reg))\n",
    "\n",
    "print(\"\\n=== NN regression metrics ===\")\n",
    "print(f\"Val  - MAE: {nn_reg_val_mae:.2f}, RMSE: {nn_reg_val_rmse:.2f}\")\n",
    "print(f\"Test - MAE: {nn_reg_test_mae:.2f}, RMSE: {nn_reg_test_rmse:.2f}\")\n",
    "\n",
    "\n",
    "# also store in a small dict for convenience (you don't have to use this, it's for us later)\n",
    "nn_results = {\n",
    "    \"clf\": {\n",
    "        \"val_accuracy\": nn_clf_val_accuracy,\n",
    "        \"val_f1\": nn_clf_val_f1,\n",
    "        \"val_roc_auc\": nn_clf_val_roc_auc,\n",
    "        \"test_accuracy\": nn_clf_test_accuracy,\n",
    "        \"test_f1\": nn_clf_test_f1,\n",
    "        \"test_roc_auc\": nn_clf_test_roc_auc,\n",
    "    },\n",
    "    \"reg\": {\n",
    "        \"val_mae\": nn_reg_val_mae,\n",
    "        \"val_rmse\": nn_reg_val_rmse,\n",
    "        \"test_mae\": nn_reg_test_mae,\n",
    "        \"test_rmse\": nn_reg_test_rmse,\n",
    "    }\n",
    "}\n",
    "\n",
    "nn_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c0b2b-5514-4932-b39c-2509a457ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4120 Project Env",
   "language": "python",
   "name": "cs4120env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
