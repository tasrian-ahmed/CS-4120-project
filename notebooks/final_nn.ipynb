{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e61102a-5760-4d00-a6cb-8b40a1c3a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 936 201 201\n",
      "Train median charges: 9545.63\n",
      "Feature matrix shape: (936, 17)\n",
      "\n",
      "=== Training classification NNs ===\n",
      "Config clf_small: hidden=(32, 16), alpha=0.001, lr=0.001\n",
      "  Final val F1 = 0.9215\n",
      "Config clf_medium: hidden=(64, 32), alpha=0.001, lr=0.0005\n",
      "  Final val F1 = 0.9110\n",
      "\n",
      "Best classification NN: clf_small with final val F1 = 0.9215\n",
      "\n",
      "=== Training regression NNs ===\n",
      "Config reg_small: hidden=(32, 16), alpha=0.001, lr=0.001\n",
      "  Final val RMSE = 4521.07\n",
      "Config reg_medium: hidden=(64, 32), alpha=0.001, lr=0.0005\n",
      "  Final val RMSE = 4370.82\n",
      "\n",
      "Best regression NN: reg_medium with final val RMSE = 4370.82\n",
      "Saved Plot 1 (classification learning curve) to ../plots/plot1_nn_class_learning_curve.png\n",
      "Saved Plot 2 (regression learning curve) to ../plots/plot2_nn_reg_learning_curve.png\n",
      "\n",
      "=== NN classification metrics ===\n",
      "Val  - Acc: 0.9254, F1: 0.9215, ROC-AUC: 0.9620\n",
      "Test - Acc: 0.9154, F1: 0.9091, ROC-AUC: 0.9432\n",
      "\n",
      "=== NN regression metrics ===\n",
      "Val  - MAE: 2543.74, RMSE: 4370.82\n",
      "Test - MAE: 2628.06, RMSE: 5046.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf': {'val_accuracy': 0.9253731343283582,\n",
       "  'val_f1': 0.9214659685863874,\n",
       "  'val_roc_auc': 0.961970570689998,\n",
       "  'test_accuracy': 0.9154228855721394,\n",
       "  'test_f1': 0.9090909090909091,\n",
       "  'test_roc_auc': 0.943154761904762},\n",
       " 'reg': {'val_mae': 2543.7399166354776,\n",
       "  'val_rmse': 4370.820926757592,\n",
       "  'test_mae': 2628.0644409321676,\n",
       "  'test_rmse': 5046.45493640548}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Imports & config ---\n",
    "import os, math, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 4120\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"../data/insurance.csv\"\n",
    "PLOTS_DIR = \"../plots\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load data and create targets (same logic as midpoint) ---\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# enforce dtypes\n",
    "cat_cols = [\"sex\", \"smoker\", \"region\"]\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# engineered features\n",
    "df[\"bmi_obese\"] = (df[\"bmi\"] >= 30).astype(int)\n",
    "df[\"age_band\"]  = pd.cut(\n",
    "    df[\"age\"],\n",
    "    bins=[17, 25, 35, 45, 55, 65],\n",
    "    labels=[\"18-25\",\"26-35\",\"36-45\",\"46-55\",\"56-65\"],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# split once\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, shuffle=True)\n",
    "val_df,   test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "train_median = train_df[\"charges\"].median()\n",
    "\n",
    "def add_targets(d, median):\n",
    "    d = d.copy()\n",
    "    d[\"y_class\"] = (d[\"charges\"] >= median).astype(int)   # high vs low cost\n",
    "    d[\"y_reg\"]   = d[\"charges\"].astype(float)\n",
    "    return d\n",
    "\n",
    "train_df = add_targets(train_df, train_median)\n",
    "val_df   = add_targets(val_df,   train_median)\n",
    "test_df  = add_targets(test_df,  train_median)\n",
    "\n",
    "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "print(\"Train median charges:\", round(train_median, 2))\n",
    "\n",
    "# --- 2. Preprocessing for NN (fit on train, transform to dense arrays) ---\n",
    "\n",
    "num_cols = [\"age\", \"bmi\", \"children\", \"bmi_obese\"]\n",
    "cat_cols = [\"sex\", \"smoker\", \"region\", \"age_band\"]\n",
    "\n",
    "numeric_tf     = StandardScaler()\n",
    "categorical_tf = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_tf, num_cols),\n",
    "        (\"cat\", categorical_tf, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_raw = train_df[num_cols + cat_cols]\n",
    "X_val_raw   = val_df[num_cols + cat_cols]\n",
    "X_test_raw  = test_df[num_cols + cat_cols]\n",
    "\n",
    "y_train_class = train_df[\"y_class\"].values\n",
    "y_val_class   = val_df[\"y_class\"].values\n",
    "y_test_class  = test_df[\"y_class\"].values\n",
    "\n",
    "y_train_reg = train_df[\"y_reg\"].values\n",
    "y_val_reg   = val_df[\"y_reg\"].values\n",
    "y_test_reg  = test_df[\"y_reg\"].values\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_reg_scaled = y_scaler.fit_transform(y_train_reg.reshape(-1, 1)).ravel()\n",
    "y_val_reg_scaled   = y_scaler.transform(y_val_reg.reshape(-1, 1)).ravel()\n",
    "y_test_reg_scaled  = y_scaler.transform(y_test_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "# fit on train, transform all\n",
    "X_train = preprocess.fit_transform(X_train_raw)\n",
    "X_val   = preprocess.transform(X_val_raw)\n",
    "X_test  = preprocess.transform(X_test_raw)\n",
    "\n",
    "# make sure dense\n",
    "if hasattr(X_train, \"toarray\"):\n",
    "    X_train = X_train.toarray()\n",
    "    X_val   = X_val.toarray()\n",
    "    X_test  = X_test.toarray()\n",
    "\n",
    "print(\"Feature matrix shape:\", X_train.shape)\n",
    "\n",
    "# --- 3. Helper: training loop for MLPClassifier (classification NN) ---\n",
    "\n",
    "def train_mlp_classifier(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    alpha=1e-3,\n",
    "    lr=1e-3,\n",
    "    epochs=80,\n",
    "):\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=1,           # we will loop manually\n",
    "        warm_start=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    classes = np.unique(y_tr)\n",
    "\n",
    "    train_f1_list = []\n",
    "    val_f1_list   = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list   = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        clf.partial_fit(X_tr, y_tr, classes=classes)\n",
    "\n",
    "        # metrics on train\n",
    "        y_tr_pred = clf.predict(X_tr)\n",
    "        train_f1  = f1_score(y_tr, y_tr_pred)\n",
    "        train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "\n",
    "        # metrics on val\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        val_f1  = f1_score(y_val, y_val_pred)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "        train_f1_list.append(train_f1)\n",
    "        val_f1_list.append(val_f1)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "    history = {\n",
    "        \"train_f1\": train_f1_list,\n",
    "        \"val_f1\":   val_f1_list,\n",
    "        \"train_acc\": train_acc_list,\n",
    "        \"val_acc\":   val_acc_list,\n",
    "    }\n",
    "    return clf, history\n",
    "\n",
    "# --- 4. Helper: training loop for MLPRegressor (regression NN) ---\n",
    "\n",
    "def train_mlp_regressor(\n",
    "    X_tr, y_tr_scaled, X_val, y_val_scaled,\n",
    "    y_tr_orig, y_val_orig,\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    alpha=1e-3,\n",
    "    lr=1e-3,\n",
    "    epochs=80,\n",
    "    y_scaler=None,\n",
    "):\n",
    "    reg = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=1,\n",
    "        warm_start=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    train_rmse_list = []\n",
    "    val_rmse_list   = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train on scaled targets\n",
    "        reg.partial_fit(X_tr, y_tr_scaled)\n",
    "\n",
    "        # Predictions in scaled space\n",
    "        y_tr_pred_scaled  = reg.predict(X_tr)\n",
    "        y_val_pred_scaled = reg.predict(X_val)\n",
    "\n",
    "        # Convert back to original dollar scale for metrics\n",
    "        if y_scaler is not None:\n",
    "            y_tr_pred = y_scaler.inverse_transform(\n",
    "                y_tr_pred_scaled.reshape(-1, 1)\n",
    "            ).ravel()\n",
    "            y_val_pred = y_scaler.inverse_transform(\n",
    "                y_val_pred_scaled.reshape(-1, 1)\n",
    "            ).ravel()\n",
    "        else:\n",
    "            y_tr_pred = y_tr_pred_scaled\n",
    "            y_val_pred = y_val_pred_scaled\n",
    "\n",
    "        # ✅ Use y_tr_orig and y_val_orig here (NOT y_tr / y_val)\n",
    "        train_rmse = math.sqrt(mean_squared_error(y_tr_orig, y_tr_pred))\n",
    "        val_rmse   = math.sqrt(mean_squared_error(y_val_orig, y_val_pred))\n",
    "\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        val_rmse_list.append(val_rmse)\n",
    "\n",
    "    history = {\n",
    "        \"train_rmse\": train_rmse_list,\n",
    "        \"val_rmse\":   val_rmse_list,\n",
    "    }\n",
    "    return reg, history\n",
    "\n",
    "\n",
    "# --- 5. Small hyperparameter grids (very small, but enough for report) ---\n",
    "\n",
    "clf_configs = [\n",
    "    {\"name\": \"clf_small\",  \"hidden\": (32, 16), \"alpha\": 1e-3, \"lr\": 1e-3},\n",
    "    {\"name\": \"clf_medium\", \"hidden\": (64, 32), \"alpha\": 1e-3, \"lr\": 5e-4},\n",
    "]\n",
    "\n",
    "reg_configs = [\n",
    "    {\"name\": \"reg_small\",  \"hidden\": (32, 16), \"alpha\": 1e-3, \"lr\": 1e-3},\n",
    "    {\"name\": \"reg_medium\", \"hidden\": (64, 32), \"alpha\": 1e-3, \"lr\": 5e-4},\n",
    "]\n",
    "\n",
    "best_clf = None\n",
    "best_clf_hist = None\n",
    "best_clf_name = None\n",
    "best_clf_val_f1 = -1\n",
    "\n",
    "print(\"\\n=== Training classification NNs ===\")\n",
    "for cfg in clf_configs:\n",
    "    print(f\"Config {cfg['name']}: hidden={cfg['hidden']}, alpha={cfg['alpha']}, lr={cfg['lr']}\")\n",
    "    model, hist = train_mlp_classifier(\n",
    "        X_train, y_train_class,\n",
    "        X_val,   y_val_class,\n",
    "        hidden_layer_sizes=cfg[\"hidden\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        epochs=80,\n",
    "    )\n",
    "    final_val_f1 = hist[\"val_f1\"][-1]\n",
    "    print(f\"  Final val F1 = {final_val_f1:.4f}\")\n",
    "    if final_val_f1 > best_clf_val_f1:\n",
    "        best_clf_val_f1 = final_val_f1\n",
    "        best_clf = model\n",
    "        best_clf_hist = hist\n",
    "        best_clf_name = cfg[\"name\"]\n",
    "\n",
    "print(f\"\\nBest classification NN: {best_clf_name} with final val F1 = {best_clf_val_f1:.4f}\")\n",
    "\n",
    "best_reg = None\n",
    "best_reg_hist = None\n",
    "best_reg_name = None\n",
    "best_reg_val_rmse = float(\"inf\")\n",
    "\n",
    "print(\"\\n=== Training regression NNs ===\")\n",
    "for cfg in reg_configs:\n",
    "    print(f\"Config {cfg['name']}: hidden={cfg['hidden']}, alpha={cfg['alpha']}, lr={cfg['lr']}\")\n",
    "    model, hist = train_mlp_regressor(\n",
    "        X_train, y_train_reg_scaled,\n",
    "        X_val,   y_val_reg_scaled,\n",
    "        y_train_reg, y_val_reg,\n",
    "        hidden_layer_sizes=cfg[\"hidden\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        epochs=80,\n",
    "        y_scaler=y_scaler,\n",
    "    )\n",
    "    final_val_rmse = hist[\"val_rmse\"][-1]\n",
    "    print(f\"  Final val RMSE = {final_val_rmse:.2f}\")\n",
    "    if final_val_rmse < best_reg_val_rmse:\n",
    "        best_reg_val_rmse = final_val_rmse\n",
    "        best_reg = model\n",
    "        best_reg_hist = hist\n",
    "        best_reg_name = cfg[\"name\"]\n",
    "\n",
    "print(f\"\\nBest regression NN: {best_reg_name} with final val RMSE = {best_reg_val_rmse:.2f}\")\n",
    "\n",
    "# --- 6. Plot learning curves (required Plot 1 & Plot 2) ---\n",
    "\n",
    "# Plot 1 – classification NN learning curve (train/val F1 vs epochs)\n",
    "epochs = range(1, len(best_clf_hist[\"train_f1\"]) + 1)\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(epochs, best_clf_hist[\"train_f1\"], label=\"Train F1\")\n",
    "ax.plot(epochs, best_clf_hist[\"val_f1\"],   label=\"Val F1\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"F1 score\")\n",
    "ax.set_title(f\"Classification NN learning curve ({best_clf_name})\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plot1_path = os.path.join(PLOTS_DIR, \"plot1_nn_class_learning_curve.png\")\n",
    "plt.savefig(plot1_path, dpi=160)\n",
    "plt.close()\n",
    "print(f\"Saved Plot 1 (classification learning curve) to {plot1_path}\")\n",
    "\n",
    "# Plot 2 – regression NN learning curve (train/val RMSE vs epochs)\n",
    "epochs = range(1, len(best_reg_hist[\"train_rmse\"]) + 1)\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(epochs, best_reg_hist[\"train_rmse\"], label=\"Train RMSE\")\n",
    "ax.plot(epochs, best_reg_hist[\"val_rmse\"],   label=\"Val RMSE\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_title(f\"Regression NN learning curve ({best_reg_name})\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plot2_path = os.path.join(PLOTS_DIR, \"plot2_nn_reg_learning_curve.png\")\n",
    "plt.savefig(plot2_path, dpi=160)\n",
    "plt.close()\n",
    "print(f\"Saved Plot 2 (regression learning curve) to {plot2_path}\")\n",
    "\n",
    "# --- 7. Final NN metrics on validation and test (for report tables) ---\n",
    "\n",
    "# Classification NN metrics\n",
    "y_val_pred_clf  = best_clf.predict(X_val)\n",
    "y_test_pred_clf = best_clf.predict(X_test)\n",
    "\n",
    "try:\n",
    "    y_val_prob_clf  = best_clf.predict_proba(X_val)[:,1]\n",
    "    y_test_prob_clf = best_clf.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    y_val_prob_clf  = y_val_pred_clf\n",
    "    y_test_prob_clf = y_test_pred_clf\n",
    "\n",
    "nn_clf_val_accuracy = accuracy_score(y_val_class, y_val_pred_clf)\n",
    "nn_clf_val_f1       = f1_score(y_val_class, y_val_pred_clf)\n",
    "nn_clf_val_roc_auc  = roc_auc_score(y_val_class, y_val_prob_clf)\n",
    "\n",
    "nn_clf_test_accuracy = accuracy_score(y_test_class, y_test_pred_clf)\n",
    "nn_clf_test_f1       = f1_score(y_test_class, y_test_pred_clf)\n",
    "nn_clf_test_roc_auc  = roc_auc_score(y_test_class, y_test_prob_clf)\n",
    "\n",
    "print(\"\\n=== NN classification metrics ===\")\n",
    "print(f\"Val  - Acc: {nn_clf_val_accuracy:.4f}, F1: {nn_clf_val_f1:.4f}, ROC-AUC: {nn_clf_val_roc_auc:.4f}\")\n",
    "print(f\"Test - Acc: {nn_clf_test_accuracy:.4f}, F1: {nn_clf_test_f1:.4f}, ROC-AUC: {nn_clf_test_roc_auc:.4f}\")\n",
    "\n",
    "# Regression NN metrics (convert predictions back to original scale)\n",
    "y_val_pred_reg_scaled  = best_reg.predict(X_val)\n",
    "y_test_pred_reg_scaled = best_reg.predict(X_test)\n",
    "\n",
    "y_val_pred_reg = y_scaler.inverse_transform(\n",
    "    y_val_pred_reg_scaled.reshape(-1, 1)\n",
    ").ravel()\n",
    "y_test_pred_reg = y_scaler.inverse_transform(\n",
    "    y_test_pred_reg_scaled.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "nn_reg_val_mae  = mean_absolute_error(y_val_reg, y_val_pred_reg)\n",
    "nn_reg_val_rmse = math.sqrt(mean_squared_error(y_val_reg, y_val_pred_reg))\n",
    "\n",
    "nn_reg_test_mae  = mean_absolute_error(y_test_reg, y_test_pred_reg)\n",
    "nn_reg_test_rmse = math.sqrt(mean_squared_error(y_test_reg, y_test_pred_reg))\n",
    "\n",
    "print(\"\\n=== NN regression metrics ===\")\n",
    "print(f\"Val  - MAE: {nn_reg_val_mae:.2f}, RMSE: {nn_reg_val_rmse:.2f}\")\n",
    "print(f\"Test - MAE: {nn_reg_test_mae:.2f}, RMSE: {nn_reg_test_rmse:.2f}\")\n",
    "\n",
    "\n",
    "# also store in a small dict for convenience (you don't have to use this, it's for us later)\n",
    "nn_results = {\n",
    "    \"clf\": {\n",
    "        \"val_accuracy\": nn_clf_val_accuracy,\n",
    "        \"val_f1\": nn_clf_val_f1,\n",
    "        \"val_roc_auc\": nn_clf_val_roc_auc,\n",
    "        \"test_accuracy\": nn_clf_test_accuracy,\n",
    "        \"test_f1\": nn_clf_test_f1,\n",
    "        \"test_roc_auc\": nn_clf_test_roc_auc,\n",
    "    },\n",
    "    \"reg\": {\n",
    "        \"val_mae\": nn_reg_val_mae,\n",
    "        \"val_rmse\": nn_reg_val_rmse,\n",
    "        \"test_mae\": nn_reg_test_mae,\n",
    "        \"test_rmse\": nn_reg_test_rmse,\n",
    "    }\n",
    "}\n",
    "\n",
    "nn_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67c0b2b-5514-4932-b39c-2509a457ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Plot 3 (confusion matrix, best NN classifier) to ../plots/plot3_confusion_matrix_best_nn.png\n"
     ]
    }
   ],
   "source": [
    "# --- Plot 3: Confusion matrix for best final classification model (NN) ---\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm_nn = confusion_matrix(y_test_class, y_test_pred_clf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_nn)\n",
    "disp.plot(cmap=\"Blues\", ax=ax, colorbar=False)\n",
    "\n",
    "ax.set_title(f\"Confusion Matrix (test) — NN classifier ({best_clf_name})\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plot3_path = os.path.join(PLOTS_DIR, \"plot3_confusion_matrix_best_nn.png\")\n",
    "plt.savefig(plot3_path, dpi=160)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved Plot 3 (confusion matrix, best NN classifier) to {plot3_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdb227b-55c4-46be-8baf-59b30eb90f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Plot 4 (residuals vs predicted, best NN regressor) to ../plots/plot4_residuals_best_nn_reg.png\n"
     ]
    }
   ],
   "source": [
    "# --- Plot 4: Residuals vs predicted for best final regression model (NN regressor) ---\n",
    "\n",
    "residuals_nn = y_test_reg - y_test_pred_reg  # true - predicted\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(y_test_pred_reg, residuals_nn, s=12, alpha=0.7)\n",
    "ax.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax.set_xlabel(\"Predicted charges (NN)\")\n",
    "ax.set_ylabel(\"Residuals (true - predicted)\")\n",
    "ax.set_title(f\"Residuals vs Predicted (test) — NN regressor ({best_reg_name})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plot4_path = os.path.join(PLOTS_DIR, \"plot4_residuals_best_nn_reg.png\")\n",
    "plt.savefig(plot4_path, dpi=160)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved Plot 4 (residuals vs predicted, best NN regressor) to {plot4_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072b03de-a858-432c-ae0f-917a864a4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features by permutation importance (tree regressor):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>smoker_no</td>\n",
       "      <td>1.560286</td>\n",
       "      <td>0.154582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.357972</td>\n",
       "      <td>0.083787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.244631</td>\n",
       "      <td>0.056047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>children</td>\n",
       "      <td>0.046630</td>\n",
       "      <td>0.031210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>region_northwest</td>\n",
       "      <td>0.030525</td>\n",
       "      <td>0.021159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>region_northeast</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>age_band_56-65</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>age_band_26-35</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.001476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>age_band_36-45</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smoker_yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance       std\n",
       "6          smoker_no    1.560286  0.154582\n",
       "1                bmi    0.357972  0.083787\n",
       "0                age    0.244631  0.056047\n",
       "2           children    0.046630  0.031210\n",
       "9   region_northwest    0.030525  0.021159\n",
       "8   region_northeast    0.022490  0.029340\n",
       "16    age_band_56-65    0.000659  0.000952\n",
       "13    age_band_26-35    0.000527  0.001476\n",
       "14    age_band_36-45    0.000103  0.000335\n",
       "7         smoker_yes    0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Plot 5 (permutation importance, tree regressor) to ../plots/plot5_feature_importance_perm_tree_reg.png\n"
     ]
    }
   ],
   "source": [
    "# --- Plot 5: Feature importance via permutation importance (Decision Tree regressor baseline) ---\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 1. Fit a Decision Tree regressor on the same preprocessed features\n",
    "tree_reg_baseline = DecisionTreeRegressor(random_state=SEED)\n",
    "tree_reg_baseline.fit(X_train, y_train_reg)\n",
    "\n",
    "# 2. Build feature names from numeric + one-hot categorical\n",
    "num_feature_names = num_cols  # [\"age\", \"bmi\", \"children\", \"bmi_obese\"]\n",
    "\n",
    "cat_onehot_names = preprocess.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)\n",
    "feature_names = list(num_feature_names) + list(cat_onehot_names)\n",
    "\n",
    "# 3. Permutation importance on test set\n",
    "perm = permutation_importance(\n",
    "    tree_reg_baseline,\n",
    "    X_test,\n",
    "    y_test_reg,\n",
    "    n_repeats=30,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "importances = perm.importances_mean\n",
    "stds = perm.importances_std\n",
    "\n",
    "# 4. Put into a DataFrame and sort\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances,\n",
    "    \"std\": stds,\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 10 features by permutation importance (tree regressor):\")\n",
    "display(feat_imp_df.head(10))\n",
    "\n",
    "# 5. Plot (bar plot of top 10)\n",
    "top_k = 10\n",
    "top_feats = feat_imp_df.head(top_k).iloc[::-1]  # reverse for nicer horizontal bar order\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.barh(top_feats[\"feature\"], top_feats[\"importance\"])\n",
    "ax.set_xlabel(\"Mean decrease in performance (permutation importance)\")\n",
    "ax.set_title(\"Permutation importance (Decision Tree regressor baseline)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plot5_path = os.path.join(PLOTS_DIR, \"plot5_feature_importance_perm_tree_reg.png\")\n",
    "plt.savefig(plot5_path, dpi=160)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved Plot 5 (permutation importance, tree regressor) to {plot5_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5ff205-a51c-4d6e-a1e1-e9fb7ca81e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL CLASSIFICATION TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg (best classical)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nn_clf_small (best NN)</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  val_accuracy  val_f1  val_roc_auc  test_accuracy  \\\n",
       "0  logreg (best classical)          0.92    0.92         0.95           0.92   \n",
       "1   nn_clf_small (best NN)          0.93    0.92         0.96           0.92   \n",
       "\n",
       "   test_f1  test_roc_auc  \n",
       "0     0.92          0.96  \n",
       "1     0.91          0.94  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL REGRESSION TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin_reg (best classical)</td>\n",
       "      <td>4261.04</td>\n",
       "      <td>5858.81</td>\n",
       "      <td>4309.84</td>\n",
       "      <td>6155.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nn_reg (best NN)</td>\n",
       "      <td>2543.74</td>\n",
       "      <td>4370.82</td>\n",
       "      <td>2628.06</td>\n",
       "      <td>5046.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_mae  val_rmse  test_mae  test_rmse\n",
       "0  lin_reg (best classical)  4261.04   5858.81   4309.84    6155.43\n",
       "1          nn_reg (best NN)  2543.74   4370.82   2628.06    5046.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved final tables to ../plots/\n"
     ]
    }
   ],
   "source": [
    "# === FINAL REPORT TABLES (Classification + Regression) ===\n",
    "\n",
    "# --- Classification comparison table ---\n",
    "clf_table = pd.DataFrame({\n",
    "    \"model\": [\"logreg (best classical)\", \"nn_clf_small (best NN)\"],\n",
    "    \"val_accuracy\": [0.92, nn_clf_val_accuracy],\n",
    "    \"val_f1\": [0.92, nn_clf_val_f1],\n",
    "    \"val_roc_auc\": [0.95, nn_clf_val_roc_auc],\n",
    "    \"test_accuracy\": [0.92, nn_clf_test_accuracy],\n",
    "    \"test_f1\": [0.92, nn_clf_test_f1],\n",
    "    \"test_roc_auc\": [0.96, nn_clf_test_roc_auc],\n",
    "})\n",
    "\n",
    "clf_table = clf_table.round(2)\n",
    "\n",
    "# --- Regression comparison table ---\n",
    "reg_table = pd.DataFrame({\n",
    "    \"model\": [\"lin_reg (best classical)\", \"nn_reg (best NN)\"],\n",
    "    \"val_mae\": [4261.04, nn_reg_val_mae],\n",
    "    \"val_rmse\": [5858.81, nn_reg_val_rmse],\n",
    "    \"test_mae\": [4309.84, nn_reg_test_mae],\n",
    "    \"test_rmse\": [6155.43, nn_reg_test_rmse],\n",
    "})\n",
    "\n",
    "reg_table = reg_table.round(2)\n",
    "\n",
    "# Display both tables\n",
    "print(\"=== FINAL CLASSIFICATION TABLE ===\")\n",
    "display(clf_table)\n",
    "\n",
    "print(\"\\n=== FINAL REGRESSION TABLE ===\")\n",
    "display(reg_table)\n",
    "\n",
    "# Save to CSV (optional but recommended)\n",
    "clf_table.to_csv(\"../plots/final_table_classification.csv\", index=False)\n",
    "reg_table.to_csv(\"../plots/final_table_regression.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved final tables to ../plots/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4120 Project Env",
   "language": "python",
   "name": "cs4120env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
